키-값 저장소(key-value store)는 비관계형(non-relational) DB이다

-   저장소 값은 고유 식별자를 키로 가지며, '키-값' 쌍이라고 지칭한다
-   키는 유일한 값이어야 하며, 일반 텍스트일 수도 있고, 해시 값일 수도 있다
-   값은 리스트일수 있고 객체일 수도 있다

## 문제 이해 및 설계 범위 확정

-   키-값 쌍의 크기는 10KB 이하이다
-   큰 데이터를 저장할수 있어야 한다
-   높은 가용성을 제공해야 한다
-   높은 규모 확장성을 제공해야 한다
-   데이터 일관성 수준은 조정 가능해야 한다
-   응답 지연시간이 짧아야 한다

## 단일 서버 키-값 저장소

한 대 서버만 사용하는 경우, 가장 쉬운 방법은 키-값 전체를 메모리에 넣는 것이다
하지만 데이터가 너무 많을 경우, 메모리 안에 두는 것이 불가능하다

따라서 이를 위해 개선책이 있다

-   데이터 압축
-   자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장

하지만 이로도 부족해지며, 분산 키-값 저장소(distributed key-value store)가 필요하게 된다

## 분산 키-값 저장소

분산 시스템을 설계할 때에는 CAP 정리를 이해해야 한다

-   Consistency
-   Availability
-   Partition Tolerance theorem

#### CAP 정리

-   데이터 일관성 (Consistency)
    -   모든 클라이언트는 어떤 노드에 접속했느냐에 관계없이 같은 데이터를 보게 되어야 한다
-   가용성 (Availability)
    -   모든 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다
-   파티션 감내 (Partition Tolerance theorem)
    -   파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다
    -   감내는 파티션이 생기더라도 시스템은 계속 동작하여야 한다는 것을 의미한다

키-값 저장소는 세가지 요구사항 가운데 두 가지를 만족하느냐에 따라 분류할 수 있다

-   CP 시스템: 가용성을 희생한다
-   AP 시스템: 데이터 일관성을 희생한다
-   CA 시스템
    -   파티션 감내는 지원하지 않는다
    -   하지만 네트워크 장애는 피할 수 없기 때문에, 만드시 감내하도록 설계되어야 한다
    -   따라서 실제 CA 시스템은 존재하지 않는다

이상적 상태

-   네트워크가 파티션되는 상황은 절대로 일어나지 않는다
-   데이터 일관성과 가용성도 만족된다

실세계의 분산 시스템

-   파티션 문제 발생시 일관성과 가용성 중 선택해야 한다
-   일관성 선택시
    -   데이터 불일치 문제를 피하기 위해 남은 노드들에 대해 쓰기 연산을 중단시켜야 한다
    -   그럴 경우, 가용성이 깨진다
    -   일관성이 깨질 수 있는 상황이라면, 상황이 해결될때까지 오류를 반환해야 한다
-   가용성 선택시
    -   오래된 데이터를 반환할 지라도 계속 읽기 연산을 허용한다
    -   또한 나머지 노드들에 대해 쓰기 연산을 허용하고, 새로운 데이터를 새로 생성된 노드에 전송하게 된다

#### 시스템 컴포넌트

데이터 파티션

-   대규모 애플리케이션의 경우, 데이터를 작은 파티션들로 분할한 다음 여러 서버에 저장한다
-   다음은 데이터를 파티션 단위로 나눌 때, 중요하게 따질 것들이다
    -   데이터를 여러 서버에 고르게 분산할 수 있는가
    -   노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가
-   이는 5장의 안정 해시(consistent hash)가 적합하며, 장점으로는 다음과 같다
    -   규모 확장 자동화 (automatic scaling)
        -   시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 만들 수 있다
    -   다양성 (heterogeneity)
        -   각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다 (고성능 서버는 더 많은 가상 노드 배치)

데이터 다중화

-   데이터를 몇몇 서버에 비동기적으로 다중화해야 높은 가용성과 안정성을 확보할 수 있다
-   서버 개수를 정하는 방법은 다음과 같다
    -   특정 키를 링 위에 배치하고, 해당 지점으로 링을 순회하면서 N개의 서버에 데이터 사본을 저장한다
    -   이 때에 N개의 노드가 대응될 실제 물리 서버는 1개가 되어버릴 수도 있다
    -   하나의 데이터 센터에 속할 경우, 동시에 정전, 네트워크 문제 등을 겪을수도 있다
    -   따라서 안정성을 담보하기 위해 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결한다

데이터 일관성

-   여러 노드에 다중화된 데이터는 적절히 동기화되어야 한다
-   정족수 합의(Quorum Consensus) 프로토콜을 사용하면 읽기, 쓰기 연산 모두에 일관성을 보장할 수 있다
    -   N = 사본 개수
    -   W = 쓰기 연산에 대한 정족수
        -   쓰기 연산이 성공한 것으로 간주하려면 적어도 W개 서버로부터 쓰기 연산 성공 응답을 받아야 한다
    -   R = 읽기 연산에 대한 정족수
        -   읽기 연산이 성공한 것으로 간주하려면 적어도 R개 서버로부터 쓰기 연산 성공 응답을 받아야 한다
-   W + R > N인 경우 강한 일관성이 보장된다
    -   R = 1, W = N: 빠른 읽기 연산에 최적화된 시스템
    -   W = 1, R = N: 빠른 쓰기 연산에 최적화된 시스템
    -   W + R > N: 강한 일관성이 보장됨
    -   W + R <= N: 강한 일관성이 보장되지 않음

일관성 모델

-   키-값 저장소를 설계할 때 고려해야할 중요한 요소이다
-   일관성 모델은 데이터 일관성의 수준을 결정하는데, 종류가 다양하다
    -   강한 일관성 (strong consistency)
        -   모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다
        -   다시 말해 클라이언트는 절대로 낡은 데이터를 보지 못한다
        -   이를 위해 모든 사본에 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기, 쓰기를 금지한다
            -   고가용성 시스템에는 적합하지 않다
    -   약한 일관성 (weak consistency)
        -   읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다
    -   최종 일관성 (eventual consistency)
        -   약한 일관성의 한 형태이다
        -   갱신 결과가 결국에는 모든 사본에 동기화되는 모델이다
        -   다이나모 또는 카산드라 같은 저장소에서 사용
        -   쓰기 연산이 병렬적으로 발생하면 일관성이 깨질 수 있으며, 클라이언트에서 해결해야 한다
            -   클라이언트에서 데이터의 버전 정보를 활용해 일관성이 깨진 데이터를 읽지 않도록 하는 기법은 아래에 설명한다

비 일관성 해소 기법: 데이터 버저닝

-   버저닝(versioning)과 벡터 시계(vector clock)는 비 일관성을 해소해준다
-   버저닝은 데이터를 변경할때마다 해당 데이터의 새로운 버전을 만든다
-   벡터 시계는 서버, 버전의 순서쌍을 데이터에 달아둔 것이다
    -   백터 시계를 사용하면 어떤 버전이 이전 버전인지 쉽게 판단할 수 있다
    -   만약 X와 Y 버전에 충돌이 있다면 (두 버전이 이전 버전에서 파생된 다른 버전인 상태), 벡터 시계 동일 서버 구성요소를 확인해야 한다
    -   벡터 시계를 사용해 충돌을 감지하고 해소하는 것은 두 가지 단점이 있다
        -   충돌 감지 및 해소 로직이 클라이언트에 들어가 구현이 복잡해진다
        -   서버, 버전의 순서쌍 개수가 빨리 늘어난다
            -   이를 위해 길이 임계치를 설정하고, 더 길어지면 벡터 시계에서 제거하도록 해야 한다
            -   하지만 버전 간 선후 관계가 정확하지 않을수도 있어, 효율성이 낮아진다
            -   실제 서비스에서 아직 이러한 문제가 발생한 적이 없다

장애 감지

-   분산 시스템에서 특정 서버에서 장애가 발생했다면, 두 대 이상의 서버가 똑같이 장애가 생긴 서버를 보고 해야 한다
-   모든 노드 사이에 멀티캐스팅 채널을 구축하면 서버 장애를 쉽게 감지할 수 있지만 서버가 많으면 비효율적이다
-   이에 대해 가십 프로토콜(gossip protocol) 같은 분산형 장애 감지(decentralized failure dectection) 솔루션이 조금 더 효율적이다
    -   각 노드는 멤버십 목록을 유지한한다
    -   멤버십 목록은 각 멤버 ID와 박동 카운터 쌍의 목록이다
    -   각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다
    -   무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다
    -   목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다
    -   어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다

일시적 장애 처리

-   장애를 감지한 시스템은 가용성을 위해 조치를 취하게 된다
    -   엄격한 정족수(strict quorum) 접근법을 쓴다면, 읽기 쓰기 연산을 금지하게 된다
    -   느슨한 정족수(sloppy quorum) 접근법은 쓰기 연산을 수행할 W개의 건강한 서버와, 읽기 연산을 수행할 R개의 건강한 서버를 해시링에서 고른다
-   장애 서버로 가는 요청은 다른 서버가 잠시 맡게 된다
    -   그동안 발생한 변경사항은 서버를 복구한 후 일관 반영하여 일관성을 유지한다

영구 장애 처리

-   반-엔트로피(anti-entropy) 프로토콜은 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함한다
-   사본 간의 일관성이 망가진 상태를 감지하고 전송 데이터 양을 줄이기 위해 머클(Merkle) 트리를 사용한다

데이터 센터 장애 처리

-   정전, 네트워크 장애, 자연 재해 등 다양한 이유로 발생할 수 있다
-   따라서 데이터를 여러 데이터 센터에 다중화하는 것이 중요하다

**시스템 아키텍처 다이어그램**

-   클라이언트는 키-값 저장소가 제공하는 두 가지 단순한 API, 즉 get, put와 통신한다
-   중재자는 클라이언트에게 키-값 저장소에 대한 프락시 역할을 하는 노드다
-   노드는 안정 해시의 해시 링 위에 분포한다
-   노드를 자동으로 추가 또는 삭제할 수 있도록, 시스템은 완전히 분산된다
-   데이터는 여러 노드에 다중화된다
-   모든 노드가 같은 책임을 지므로, SPOF는 존재하지 않는다

**쓰기 경로**

-   쓰기 요청이 올 경우 카산드라의 사례
    1. 쓰기 요청이 커밋 로그 파일에 기록된다
    2. 데이터가 메모리 캐시에 기록된다
    3. 메모리 캐시가 가득차거나 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다
        - SSTable은 Sorted-String Table의 약어로, <키,값> 순섰아을 정렬된 리스트 형태로 관리하는 테이블이다

**읽기 경로**

-   읽기 요청을 받은 노드는 데이터가 메모리 캐시에 있는지부터 살핀다
    -   있을 경우 클라이언트에게 반환한다
    -   업승ㄹ 경우 디스크에서 가져와서 반환한다
        -   이 때 어느 SSTable에 있는지 확인하기 위해 블룸 필터를 사용한다
        -
